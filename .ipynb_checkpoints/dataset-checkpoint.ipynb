{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # 파이토치\n",
    "import torch.nn as nn # 레이어, 활성화함수 등 basic building blocks이 들어있습니다.\n",
    "import torchvision.transforms as transforms # 변환 연산(resize 등)이 들어있는 모듈입니다. \n",
    "from torchvision.datasets import VOCDetection # PASCAL VOC 2007을 가져오는데 쓰입니다. 클래스 형식으로 만들어져 사용을 편리하게 할 수 있습니다.\n",
    "\n",
    "import xmltodict # xml파일의 내용을 딕셔너리에 저장할 수 있는 메소드들이 들어있는 모듈입니다. \n",
    "from PIL import Image # 이미지를 읽기 위해 사용합니다\n",
    "import numpy as np # 넘파이, 저는 넘파이로 연산하는게 익숙해 넘파이를 사용합니다.\n",
    "from tqdm import tqdm # tqdm, for문의 진행상황을 보기 위해 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO_PASCAL_VOC(VOCDetection):\n",
    "    def __getitem__(self, index):\n",
    "        img = (Image.open(self.images[index]).convert('RGB')).resize((224, 224))\n",
    "        img_transform = transforms.Compose([transforms.PILToTensor(), transforms.Resize((224, 224))])\n",
    "        img = torch.divide(img_transform(img), 255)\n",
    "\n",
    "\n",
    "        target = xmltodict.parse(open(self.annotations[index]).read())\n",
    "\n",
    "        classes = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "                   \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "                   \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "                   \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "        label = np.zeros((7, 7, 25), dtype = float)\n",
    "\n",
    "        Image_Height = float(target['annotation']['size']['height'])\n",
    "        Image_Width  = float(target['annotation']['size']['width'])\n",
    "\n",
    "        # 바운딩 박스 정보 받아오기\n",
    "        try:\n",
    "            for obj in target['annotation']['object']:\n",
    "                \n",
    "                # class의 index 휙득\n",
    "                class_index = classes.index(obj['name'].lower())\n",
    "                \n",
    "                # min, max좌표 얻기\n",
    "                x_min = float(obj['bndbox']['xmin']) \n",
    "                y_min = float(obj['bndbox']['ymin'])\n",
    "                x_max = float(obj['bndbox']['xmax']) \n",
    "                y_max = float(obj['bndbox']['ymax'])\n",
    "\n",
    "                # 224*224에 맞게 변형시켜줌\n",
    "                x_min = float((224.0/Image_Width)*x_min)\n",
    "                y_min = float((224.0/Image_Height)*y_min)\n",
    "                x_max = float((224.0/Image_Width)*x_max)\n",
    "                y_max = float((224.0/Image_Height)*y_max)\n",
    "\n",
    "                # 변형시킨걸 x,y,w,h로 만들기 \n",
    "                x = (x_min + x_max)/2.0\n",
    "                y = (y_min + y_max)/2.0\n",
    "                w = x_max - x_min\n",
    "                h = y_max - y_min\n",
    "\n",
    "                # x,y가 속한 cell알아내기\n",
    "                x_cell = int(x/32) # 0~6\n",
    "                y_cell = int(y/32) # 0~6\n",
    "                # cell의 중심 좌표는 (0.5, 0.5)다\n",
    "                x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "                y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "\n",
    "                # w, h 를 0~1 사이의 값으로 만들기\n",
    "                w = w / 224.0\n",
    "                h = h / 224.0\n",
    "\n",
    "                class_index_inCell = class_index + 5\n",
    "\n",
    "                label[y_cell][x_cell][0] = x_val_inCell\n",
    "                label[y_cell][x_cell][1] = y_val_inCell\n",
    "                label[y_cell][x_cell][2] = w\n",
    "                label[y_cell][x_cell][3] = h\n",
    "                label[y_cell][x_cell][4] = 1.0\n",
    "                label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    "\n",
    "\n",
    "        # single-object in image\n",
    "        except TypeError as e : \n",
    "            # class의 index 휙득\n",
    "            class_index = classes.index(target['annotation']['object']['name'].lower())\n",
    "                \n",
    "            # min, max좌표 얻기\n",
    "            x_min = float(target['annotation']['object']['bndbox']['xmin']) \n",
    "            y_min = float(target['annotation']['object']['bndbox']['ymin'])\n",
    "            x_max = float(target['annotation']['object']['bndbox']['xmax']) \n",
    "            y_max = float(target['annotation']['object']['bndbox']['ymax'])\n",
    "\n",
    "            # 224*224에 맞게 변형시켜줌\n",
    "            x_min = float((224.0/Image_Width)*x_min)\n",
    "            y_min = float((224.0/Image_Height)*y_min)\n",
    "            x_max = float((224.0/Image_Width)*x_max)\n",
    "            y_max = float((224.0/Image_Height)*y_max)\n",
    "\n",
    "            # 변형시킨걸 x,y,w,h로 만들기 \n",
    "            x = (x_min + x_max)/2.0\n",
    "            y = (y_min + y_max)/2.0\n",
    "            w = x_max - x_min\n",
    "            h = y_max - y_min\n",
    "\n",
    "            # x,y가 속한 cell알아내기\n",
    "            x_cell = int(x/32) # 0~6\n",
    "            y_cell = int(y/32) # 0~6\n",
    "            x_val_inCell = float((x - x_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "            y_val_inCell = float((y - y_cell * 32.0)/32.0) # 0.0 ~ 1.0\n",
    "\n",
    "            # w, h 를 0~1 사이의 값으로 만들기\n",
    "            w = w / 224.0\n",
    "            h = h / 224.0\n",
    "\n",
    "            class_index_inCell = class_index + 5\n",
    "\n",
    "            label[y_cell][x_cell][0] = x_val_inCell\n",
    "            label[y_cell][x_cell][1] = y_val_inCell\n",
    "            label[y_cell][x_cell][2] = w\n",
    "            label[y_cell][x_cell][3] = h\n",
    "            label[y_cell][x_cell][4] = 1.0\n",
    "            label[y_cell][x_cell][class_index_inCell] = 1.0\n",
    "            \n",
    "        return img, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(torch.nn.Module):\n",
    "    def __init__(self, VGG16):\n",
    "        super(YOLO, self).__init__()\n",
    "        self.backbone = VGG16\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512,out_channels = 1024, kernel_size = 3, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 1024,out_channels = 1024, kernel_size = 3, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(in_channels = 1024,out_channels = 1024, kernel_size = 3, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 1024,out_channels = 1024, kernel_size = 3, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(7*7*1024, 4096),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1470)\n",
    "        )\n",
    "\n",
    "        # 가중치 초기화\n",
    "        for m in self.conv.modules():\n",
    "    \t    if isinstance(m, nn.Conv2d) :\n",
    "\t\t        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "                \n",
    "        for m in self.linear.modules():\n",
    "        \tif isinstance(m, nn.Linear) :\n",
    "                 nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "                \n",
    "\n",
    "    # 정전파 \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.linear(out)\n",
    "        out = torch.reshape(out, (-1 ,7, 7, 30))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_multitask_loss(y_pred, y_true): # 커스텀 손실함수. 배치 단위로 값이 들어온다\n",
    "    \n",
    "    batch_loss = 0\n",
    "    count = len(y_true)\n",
    "    for i in range(0, len(y_true)) :\n",
    "        y_true_unit = y_true[i].clone().detach().requires_grad_(True)\n",
    "\n",
    "        y_pred_unit = y_pred[i].clone().detach().requires_grad_(True)\n",
    "\n",
    "        y_true_unit = torch.reshape(y_true_unit, [49, 25])\n",
    "        y_pred_unit = torch.reshape(y_pred_unit, [49, 30])\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        for j in range(0, len(y_true_unit)) :\n",
    "            # pred = [1, 30], true = [1, 25]\n",
    "            \n",
    "            bbox1_pred = y_pred_unit[j, :4].clone().detach().requires_grad_(True)\n",
    "            bbox1_pred_confidence = y_pred_unit[j, 4].clone().detach().requires_grad_(True)\n",
    "            bbox2_pred = y_pred_unit[j, 5:9].clone().detach().requires_grad_(True)\n",
    "            bbox2_pred_confidence = y_pred_unit[j, 9].clone().detach().requires_grad_(True)\n",
    "            class_pred = y_pred_unit[j, 10:].clone().detach().requires_grad_(True)\n",
    "            \n",
    "            bbox_true = y_true_unit[j, :4].clone().detach().requires_grad_(True)\n",
    "            bbox_true_confidence = y_true_unit[j, 4].clone().detach().requires_grad_(True)\n",
    "            class_true = y_true_unit[j, 5:].clone().detach().requires_grad_(True)\n",
    "            \n",
    "            # IoU 구하기\n",
    "            # x,y,w,h -> min_x, min_y, max_x, max_y로 변환\n",
    "            box_pred_1_np = bbox1_pred.detach().numpy()\n",
    "            box_pred_2_np = bbox2_pred.detach().numpy()\n",
    "            box_true_np   = bbox_true.detach().numpy()\n",
    "\n",
    "            box_pred_1_area = box_pred_1_np[2] * box_pred_1_np[3]\n",
    "            box_pred_2_area = box_pred_2_np[2] * box_pred_2_np[3]\n",
    "            box_true_area   = box_true_np[2]  * box_true_np[3]\n",
    "\n",
    "            box_pred_1_minmax = np.asarray([box_pred_1_np[0] - 0.5*box_pred_1_np[2], box_pred_1_np[1] - 0.5*box_pred_1_np[3], box_pred_1_np[0] + 0.5*box_pred_1_np[2], box_pred_1_np[1] + 0.5*box_pred_1_np[3]])\n",
    "            box_pred_2_minmax = np.asarray([box_pred_2_np[0] - 0.5*box_pred_2_np[2], box_pred_2_np[1] - 0.5*box_pred_2_np[3], box_pred_2_np[0] + 0.5*box_pred_2_np[2], box_pred_2_np[1] + 0.5*box_pred_2_np[3]])\n",
    "            box_true_minmax   = np.asarray([box_true_np[0] - 0.5*box_true_np[2], box_true_np[1] - 0.5*box_true_np[3], box_true_np[0] + 0.5*box_true_np[2], box_true_np[1] + 0.5*box_true_np[3]])\n",
    "\n",
    "            # 곂치는 영역의 (min_x, min_y, max_x, max_y)\n",
    "            InterSection_pred_1_with_true = [max(box_pred_1_minmax[0], box_true_minmax[0]), max(box_pred_1_minmax[1], box_true_minmax[1]), min(box_pred_1_minmax[2], box_true_minmax[2]), min(box_pred_1_minmax[3], box_true_minmax[3])]\n",
    "            InterSection_pred_2_with_true = [max(box_pred_2_minmax[0], box_true_minmax[0]), max(box_pred_2_minmax[1], box_true_minmax[1]), min(box_pred_2_minmax[2], box_true_minmax[2]), min(box_pred_2_minmax[3], box_true_minmax[3])]\n",
    "\n",
    "            # 박스별로 IoU를 구한다\n",
    "            IntersectionArea_pred_1_true = 0\n",
    "\n",
    "            # 음수 * 음수 = 양수일 수도 있으니 검사를 한다.\n",
    "            if (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1) >= 0 and (InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1) >= 0 :\n",
    "                    IntersectionArea_pred_1_true = (InterSection_pred_1_with_true[2] - InterSection_pred_1_with_true[0] + 1) * InterSection_pred_1_with_true[3] - InterSection_pred_1_with_true[1] + 1\n",
    "\n",
    "            IntersectionArea_pred_2_true = 0\n",
    "\n",
    "            if (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1) >= 0 and (InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1) >= 0 :\n",
    "                    IntersectionArea_pred_2_true = (InterSection_pred_2_with_true[2] - InterSection_pred_2_with_true[0] + 1) * InterSection_pred_2_with_true[3] - InterSection_pred_2_with_true[1] + 1\n",
    "\n",
    "            Union_pred_1_true = box_pred_1_area + box_true_area - IntersectionArea_pred_1_true\n",
    "            Union_pred_2_true = box_pred_2_area + box_true_area - IntersectionArea_pred_2_true\n",
    "\n",
    "            IoU_box_1 = IntersectionArea_pred_1_true/Union_pred_1_true\n",
    "            IoU_box_2 = IntersectionArea_pred_2_true/Union_pred_2_true\n",
    "                        \n",
    "            responsible_box = 0\n",
    "            responsible_bbox_confidence = 0\n",
    "            non_responsible_bbox_confidence = 0\n",
    "\n",
    "            # box1, box2 중 responsible한걸 선택(IoU 기준)\n",
    "            if IoU_box_1 >= IoU_box_2 :\n",
    "                responsible_box = bbox1_pred.clone().detach().requires_grad_(True)\n",
    "                responsible_bbox_confidence = bbox1_pred_confidence.clone().detach().requires_grad_(True)\n",
    "                non_responsible_bbox_confidence = bbox2_pred_confidence.clone().detach().requires_grad_(True)\n",
    "                                \n",
    "            else :\n",
    "                responsible_box = bbox2_pred.clone().detach().requires_grad_(True)\n",
    "                responsible_bbox_confidence = bbox2_pred_confidence.clone().detach().requires_grad_(True)\n",
    "                non_responsible_bbox_confidence = bbox1_pred_confidence.clone().detach().requires_grad_(True)\n",
    "                \n",
    "            # 1obj(i) 정하기(해당 셀에 객체의 중심좌표가 들어있는가?)\n",
    "            obj_exist = torch.ones_like(bbox_true_confidence)\n",
    "            if box_true_np[0] == 0.0 and box_true_np[1] == 0.0 and box_true_np[2] == 0.0 and box_true_np[3] == 0.0 : \n",
    "                obj_exist = torch.zeros_like(bbox_true_confidence) \n",
    "            \n",
    "                        \n",
    "            # 만약 해당 cell에 객체가 없으면 confidence error의 no object 파트만 판단. (label된 값에서 알아서 해결)\n",
    "            # 0~3 : bbox1의 위치 정보, 4 : bbox1의 bbox confidence score, 5~8 : bbox2의 위치 정보, 9 : bbox2의 confidence score, 10~29 : cell에 존재하는 클래스 확률 = pr(class | object) \n",
    "\n",
    "            # localization error 구하기(x,y,w,h). x, y는 해당 grid cell의 중심 좌표와 offset이고 w, h는 전체 이미지에 대해 정규화된 값이다. 즉, 범위가 0~1이다.\n",
    "            localization_err_x = torch.pow( torch.subtract(bbox_true[0], responsible_box[0]), 2) # (x-x_hat)^2\n",
    "            localization_err_y = torch.pow( torch.subtract(bbox_true[1], responsible_box[1]), 2) # (y-y_hat)^2\n",
    "\n",
    "            localization_err_w = torch.pow( torch.subtract(torch.sqrt(bbox_true[2]), torch.sqrt(responsible_box[2])), 2) # (sqrt(w) - sqrt(w_hat))^2\n",
    "            localization_err_h = torch.pow( torch.subtract(torch.sqrt(bbox_true[3]), torch.sqrt(responsible_box[3])), 2) # (sqrt(h) - sqrt(h_hat))^2\n",
    "            \n",
    "            # nan 방지\n",
    "            if torch.isnan(localization_err_w).detach().numpy() == True :\n",
    "                localization_err_w = torch.zeros_like(localization_err_w)\n",
    "            \n",
    "            if torch.isnan(localization_err_h).detach().numpy() == True :\n",
    "                localization_err_h = torch.zeros_like(localization_err_h)\n",
    "            \n",
    "            localization_err_1 = torch.add(localization_err_x, localization_err_y)\n",
    "            localization_err_2 = torch.add(localization_err_w, localization_err_h)\n",
    "            localization_err = torch.add(localization_err_1, localization_err_2)\n",
    "            \n",
    "            weighted_localization_err = torch.multiply(localization_err, 5.0) # 5.0 : λ_coord\n",
    "            weighted_localization_err = torch.multiply(weighted_localization_err, obj_exist) # 1obj(i) 곱하기\n",
    "            \n",
    "            # confidence error 구하기. true의 경우 답인 객체는 1 * ()고 아니면 0*()가 된다. \n",
    "            # index 4, 9에 있는 값(0~1)이 해당 박스에 객체가 있을 확률을 나타낸거다. Pr(obj in bbox)\n",
    "            \n",
    "            class_confidence_score_obj = torch.pow(torch.subtract(responsible_bbox_confidence, bbox_true_confidence), 2)\n",
    "            class_confidence_score_noobj = torch.pow(torch.subtract(non_responsible_bbox_confidence, torch.zeros_like(bbox_true_confidence)), 2)\n",
    "            class_confidence_score_noobj = torch.multiply(class_confidence_score_noobj, 0.5)\n",
    "            \n",
    "            class_confidence_score_obj = torch.mul(class_confidence_score_obj, obj_exist)\n",
    "            class_confidence_score_noobj = torch.mul(class_confidence_score_noobj, torch.subtract(torch.ones_like(obj_exist), obj_exist)) # 객체가 존재하면 0, 존재하지 않으면 1을 곱합\n",
    "            \n",
    "            class_confidence_score = torch.add(class_confidence_score_obj,  class_confidence_score_noobj) \n",
    "            \n",
    "            # classification loss(10~29. 인덱스 10~29에 해당되는 값은 Pr(Class_i|Object)이다. 객체가 cell안에 있을 때 해당 객체일 확률\n",
    "            # class_true_oneCell는 진짜 객체의 인덱스에 해당하ㄴ 원소의 값만 1이고 나머지는 0 \n",
    "            \n",
    "            torch.pow(torch.subtract(class_true, class_pred), 2.0) # 여기서 에러\n",
    "            \n",
    "            classification_err = torch.pow(torch.subtract(class_true, class_pred), 2.0)\n",
    "            classification_err = torch.sum(classification_err)\n",
    "            classification_err = torch.multiply(classification_err, obj_exist)\n",
    "            \n",
    "            # loss합체\n",
    "            loss_OneCell_1 = torch.add(weighted_localization_err, class_confidence_score)\n",
    "            \n",
    "            loss_OneCell = torch.add(loss_OneCell_1, classification_err)\n",
    "            \n",
    "            if loss == 0 :\n",
    "                loss = loss_OneCell.clone().detach().requires_grad_(True)\n",
    "            else :\n",
    "                loss = torch.add(loss, loss_OneCell)\n",
    "        \n",
    "        if batch_loss == 0 :\n",
    "            batch_loss = loss.clone().detach().requires_grad_(True)\n",
    "        else :\n",
    "            batch_loss = torch.add(batch_loss, loss)\n",
    "        \n",
    "    # 배치에 대한 loss 구하기\n",
    "    batch_loss = torch.divide(batch_loss, count)\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_YOLO(YOLO_model, criterion, optimizer, epochs, data_loader, device) :\n",
    "    # 학습 -> 성능 측정\n",
    "\n",
    "    pbar = tqdm(range(epochs), desc=\"training\", mininterval=0.01)\n",
    "\n",
    "    for epoch in pbar:  # loop over the dataset multiple times\n",
    "        optimizer.param_groups[0]['lr']\n",
    "        if epoch >=0 and epoch < 75 :\n",
    "            optimizer.param_groups[0]['lr'] = 0.001 + 0.009 * (float(epoch)/(75.0)) # 가중치를 0.001 ~ 0.01로 변경\n",
    "        elif epoch >= 75 and epoch < 105 :\n",
    "            optimizer.param_groups[0]['lr'] = 0.001\n",
    "        else : \n",
    "            optimizer.param_groups[0]['lr'] = 0.0001\n",
    "            \n",
    "        for inputs, labels in data_loader:\n",
    "\t\t\t\n",
    "            # 데이터 꺼내기(배치 단위)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\t\t\t\n",
    "            optimizer.zero_grad() # 그레디언트 초기화\n",
    "             \n",
    "            outputs = YOLO_model(inputs) # 예측값 휙득 \n",
    "            loss = criterion(outputs, labels) # loss 휙득\n",
    "            loss.backward() # 그레디언트 구하기\n",
    "            optimizer.step() # 구한 그레이던트를 이용해 가중치 업데이트\n",
    "\n",
    "            # 배치로 학습시킬 때마다 loss 보여주기\n",
    "            pbar_str = \"training, [loss = %.4f]\" % loss.item()\n",
    "            pbar.set_description(pbar_str)\n",
    "            \n",
    "    return YOLO_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb  3 21:29:16 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN V             Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 36%   47C    P2    52W / 250W |   8469MiB / 12066MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:D9:00.0 Off |                  N/A |\n",
      "| 49%   60C    P2   108W / 280W |  14220MiB / 24220MiB |     23%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     39120      C   python3                          8457MiB |\n",
      "|    1   N/A  N/A     38959      C   python3                         14201MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar to /home/mskang/hyeokjong/object_detection/voc/VOCtest_06-Nov-2007.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7090e6251cc14ecdb6944a55832856c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/451020800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/mskang/hyeokjong/object_detection/voc/VOCtest_06-Nov-2007.tar to /home/mskang/hyeokjong/object_detection/voc\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/mskang/hyeokjong/object_detection/voc/VOCdevkit/VOC2007/ImageSets/Main/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2717/3618833077.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 데이터셋을 편하게 사용할 수 있는 데이터셋 클래스의 객체를 선언합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 만약 데이터셋이 없으면 해당 데이터셋이 있을 경로(path2data)에 데이터셋을 다운로드합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mTrain_Dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO_PASCAL_VOC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2007'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mTest_Dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO_PASCAL_VOC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2007'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hyeokjong2/lib/python3.7/site-packages/torchvision/datasets/voc.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, year, image_set, download, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msplits_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ImageSets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SPLITS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0msplit_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/mskang/hyeokjong/object_detection/voc/VOCdevkit/VOC2007/ImageSets/Main/train.txt'"
     ]
    }
   ],
   "source": [
    "# VOC 2007 dataset의 위치를 저장합니다. \n",
    "current_path = os.getcwd()\n",
    "path2data = current_path + '/voc'\n",
    "if not os.path.exists(path2data): # 만약 데이터셋이 저장되어 있지 않다면 \n",
    "    os.mkdir(path2data) # 저장할 폴더를 생성합니다. \n",
    "    \n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 135\n",
    "\n",
    "# 데이터셋을 편하게 사용할 수 있는 데이터셋 클래스의 객체를 선언합니다.\n",
    "# 만약 데이터셋이 없으면 해당 데이터셋이 있을 경로(path2data)에 데이터셋을 다운로드합니다.\n",
    "Train_Dataset = YOLO_PASCAL_VOC(path2data, year='2007', image_set='train', download=True)\n",
    "Test_Dataset = YOLO_PASCAL_VOC(path2data, year='2007', image_set='test', download=True)\n",
    "\n",
    "# 생성한 데이터셋 객체로 DataLoader 객체를 생성합니다.\n",
    "# DataLoader를 이용하면 미니배치 단위로 모델에 데이터를 넣는 것이 매우 쉬워집니다.\n",
    "# 즉, 학습시키는 코드를 쉽게 구현할 수 있게 해줍니다.\n",
    "data_loader = torch.utils.data.DataLoader(dataset=Train_Dataset, # 사용할 데이터셋\n",
    "                                          batch_size=BATCH_SIZE, # 미니배치 크기\n",
    "                                          shuffle=True, # 에포크마다 데이터셋 셔플할건가? \n",
    "                                          drop_last=True) # 마지막 배치가 BATCH_SIZE보다 작을 때, 마지막 배치를 사용하지 않으려면 True를, 사용할거면 False를 입력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                                          \n",
    "# 사전학습된 VGG16을 불러옵니다. \n",
    "VGGNet = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16', pretrained=True)\n",
    "# VGG16에 있는 레이어 중 제가 사용할 레이어들이 그레디언트 추적을 못하게 해 가중치 변화를 막고\n",
    "# padding을 1로 만들어 same padding이 되게끔 만들어줍니다.\n",
    "for i in range(len(VGGNet.features[:-1])) :\n",
    "    if type(VGGNet.features[i]) == type(nn.Conv2d(64,64,3)) :\n",
    "        VGGNet.features[i].weight.requires_grad = False\n",
    "        VGGNet.features[i].bias.requires_grad = False\n",
    "        VGGNet.features[i].padding = 1\n",
    "\n",
    "# YOLO와 optimizer를 선언합니다. VGGNet.features[:-1]는 VGG16에서 제가 Backbone으로 사용할 레이어들을 말합니다.\n",
    "YOLO_model =  YOLO(VGGNet.features[:-1]).to(device) # Create YOLO model\n",
    "optimizer = torch.optim.SGD(YOLO_model.parameters(), lr = 0.01, momentum = 0.9, weight_decay=0.0005)\n",
    "\n",
    "# 모델을 학습시킵니다.\n",
    "YOLO_model = train_YOLO(YOLO_model, yolo_multitask_loss, optimizer, EPOCH, data_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c3c7152b532fd28c217869295ba0fbb2b6716303accc13f15426c445bfbdae4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
